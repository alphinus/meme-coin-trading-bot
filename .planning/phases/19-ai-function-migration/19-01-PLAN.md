---
phase: 19-ai-function-migration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - server/src/agent/warm-session.ts
  - server/src/app.ts
autonomous: true

must_haves:
  truths:
    - "A warm Agent SDK session starts at server boot and accepts lightweight AI requests"
    - "Concurrent AI requests are queued and processed sequentially via async FIFO"
    - "Only one cold start occurs (at boot), subsequent requests respond in under 3 seconds"
  artifacts:
    - path: "server/src/agent/warm-session.ts"
      provides: "WarmAgentSession singleton with generate() method and async request queue"
      exports: ["warmSession"]
    - path: "server/src/app.ts"
      provides: "Warm session initialization at server startup"
      contains: "warmSession.start()"
  key_links:
    - from: "server/src/agent/warm-session.ts"
      to: "@anthropic-ai/claude-agent-sdk"
      via: "query() with AsyncIterable prompt for streaming input"
      pattern: "import.*query.*from.*claude-agent-sdk"
    - from: "server/src/app.ts"
      to: "server/src/agent/warm-session.ts"
      via: "startup initialization call"
      pattern: "warmSession\\.start"
---

<objective>
Create the WarmAgentSession singleton that starts a single long-lived Agent SDK query() call at server boot and exposes a generate() method for lightweight AI requests without cold-start overhead.

Purpose: Eliminate ~12s cold start per AI call by amortizing it to a single boot-time cost. This singleton is the foundation all gateway functions will delegate to in subsequent plans.
Output: `server/src/agent/warm-session.ts` exporting `warmSession`, integrated into `server/src/app.ts` startup.
</objective>

<execution_context>
@/Users/developer/.claude/get-shit-done/workflows/execute-plan.md
@/Users/developer/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/19-ai-function-migration/19-RESEARCH.md
@server/src/agent/session-manager.ts
@server/src/agent/types.ts
@server/src/app.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create WarmAgentSession singleton with async FIFO queue</name>
  <files>server/src/agent/warm-session.ts</files>
  <action>
Create `server/src/agent/warm-session.ts` implementing the WarmAgentSession class:

1. **Class structure:**
   - Private `queryInstance` holding the active query() return value
   - Private async FIFO queue: array of pending requests, each with `{ systemPrompt, userPrompt, taskType, resolve, reject }`
   - Private `processing` boolean to ensure sequential execution
   - Private `started` boolean guard

2. **start() method:**
   - Creates a single `query()` call using the stable v1 API from `@anthropic-ai/claude-agent-sdk`
   - Uses `prompt: string` (initial prompt) -- NOT AsyncIterable (simpler approach for lightweight calls)
   - Options: `model: "claude-haiku-4-5"`, `maxTurns: 1`, `persistSession: false`, `permissionMode: "plan"`, `settingSources: []`
   - Consumes the initial response stream to complete the cold start
   - Sets `started = true`
   - Logs `[warm-session] Started warm agent session` on success
   - Logs warning and continues if start fails (server still boots, AI calls fall back to error)

3. **generate() method:**
   - Signature: `generate(options: { systemPrompt: string; userPrompt: string; taskType: string }): Promise<string>`
   - If not started, throw clear error: "Warm session not started"
   - Enqueues the request into the FIFO queue
   - Returns a promise that resolves when the request is processed
   - **Implementation approach:** Since each lightweight call is independent (no multi-turn conversation needed), create a new short-lived `query()` call per request BUT reuse the subprocess. Actually, per research Pitfall 1, creating new query() per call IS the cold-start problem.
   - **Revised approach:** Use the warm session pattern where the initial query() stays alive. For each generate() call, use `queryInstance.streamInput()` to send a new user message, then collect the response from the async iterator.
   - The message format should include both system context and user prompt in a single user message: `"[System: ${systemPrompt}]\n\n${userPrompt}"`
   - Parse the text response from the SDK message stream (look for `type: "text"` or `type: "result"` messages)

4. **processQueue() method (private):**
   - If already processing or queue is empty, return
   - Dequeue the next request
   - Call streamInput() with the formatted message
   - Collect response text from the query's async iterator
   - Resolve the promise with the collected text
   - On error, reject the promise with descriptive error
   - Recursively call processQueue() to handle next item

5. **Export:**
   - `export const warmSession = new WarmAgentSession();`

**Important implementation notes:**
- Study the SDK types in `node_modules/@anthropic-ai/claude-agent-sdk/sdk.d.ts` for exact `streamInput()` and message type signatures
- The `query()` return type is `AsyncGenerator<SDKMessage>` with a `.streamInput()` method
- Handle the case where the query stream ends unexpectedly (restart the session)
- Use `try/catch` around all SDK calls with clear error messages prefixed with `[warm-session]`

**If streamInput() is not viable** (SDK limitation discovered at implementation time): Fall back to creating a new `query()` per generate() call but log a warning about cold-start impact. The FIFO queue still prevents concurrent SDK calls. This is acceptable as a degraded mode -- the important thing is the abstraction exists for all gateways to use.
  </action>
  <verify>
1. File exists: `ls server/src/agent/warm-session.ts`
2. TypeScript compiles without NEW errors: `npx tsc --noEmit 2>&1 | grep -c "error TS"` should not increase beyond pre-existing 19 errors
3. Export check: `grep "export const warmSession" server/src/agent/warm-session.ts` returns a match
4. Has generate method: `grep "async generate" server/src/agent/warm-session.ts` returns a match
5. Has queue mechanism: `grep -E "queue|Queue|processQueue" server/src/agent/warm-session.ts` returns matches
  </verify>
  <done>WarmAgentSession singleton exists with start(), generate(), and async FIFO queue. Exports warmSession instance.</done>
</task>

<task type="auto">
  <name>Task 2: Integrate warm session startup into app.ts</name>
  <files>server/src/app.ts</files>
  <action>
Modify `server/src/app.ts` to start the warm session at server boot:

1. Add import at top: `import { warmSession } from "./agent/warm-session.js";`
2. After the `checkAgentAuth()` call (line 38), add warm session initialization:
   ```
   // Start warm Agent SDK session for lightweight AI calls
   warmSession.start().catch((err) => {
     console.error("[app] Failed to start warm agent session:", err instanceof Error ? err.message : String(err));
   });
   ```
3. In the `gracefulShutdown` function, add cleanup before process.exit:
   ```
   warmSession.stop(); // if stop() method exists, otherwise skip
   ```

The warm session start is fire-and-forget (non-blocking). The server continues booting while the cold start completes in the background. If it fails, AI calls will get clear errors when they try to use generate().
  </action>
  <verify>
1. Import present: `grep "warm-session" server/src/app.ts` returns a match
2. Startup call present: `grep "warmSession.start" server/src/app.ts` returns a match
3. Server builds: `cd /Users/developer/eluma && npx tsc --noEmit 2>&1 | tail -5` -- verify no new TS errors
  </verify>
  <done>Server starts warm Agent SDK session at boot. Cold start is amortized once. generate() is available for all gateway functions.</done>
</task>

</tasks>

<verification>
1. `ls server/src/agent/warm-session.ts` -- file exists
2. `grep "export const warmSession" server/src/agent/warm-session.ts` -- singleton exported
3. `grep "warmSession.start" server/src/app.ts` -- integrated into boot
4. TypeScript error count has not increased beyond pre-existing 19
</verification>

<success_criteria>
- WarmAgentSession singleton exists at `server/src/agent/warm-session.ts`
- Exports `warmSession` with `start()` and `generate()` methods
- Async FIFO queue prevents concurrent SDK calls
- `server/src/app.ts` calls `warmSession.start()` at boot
- No new TypeScript compilation errors introduced
</success_criteria>

<output>
After completion, create `.planning/phases/19-ai-function-migration/19-01-SUMMARY.md`
</output>
