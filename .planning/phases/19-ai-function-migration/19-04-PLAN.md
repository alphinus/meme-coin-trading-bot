---
phase: 19-ai-function-migration
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - server/src/voice/transcribe.ts
autonomous: true

must_haves:
  truths:
    - "Voice transcription uses local whisper.cpp binary instead of OpenAI Whisper API"
    - "No OPENAI_API_KEY is needed for voice transcription"
    - "Audio buffer is written to temp file, transcribed by whisper-cli, temp file is cleaned up"
    - "Telegram voice handler and web voice upload both work with the new transcription"
  artifacts:
    - path: "server/src/voice/transcribe.ts"
      provides: "transcribeAudio() using local whisper-cli binary"
      exports: ["transcribeAudio", "TranscriptionResult"]
  key_links:
    - from: "server/src/voice/transcribe.ts"
      to: "/Users/developer/whisper.cpp/build/bin/whisper-cli"
      via: "child_process.execFile() call"
      pattern: "execFile.*whisper-cli"
    - from: "server/src/routes/voice.ts"
      to: "server/src/voice/transcribe.ts"
      via: "import transcribeAudio"
      pattern: "transcribeAudio"
    - from: "server/src/telegram/handlers/voice.ts"
      to: "server/src/voice/transcribe.ts"
      via: "import transcribeAudio"
      pattern: "transcribeAudio"
---

<objective>
Replace OpenAI Whisper API transcription with local whisper.cpp binary invocation. Voice transcription becomes fully local with zero cloud cost and no API key dependency.

Purpose: Eliminate the OPENAI_API_KEY dependency and cloud transcription costs. The whisper.cpp binary is already built at `/Users/developer/whisper.cpp/build/bin/whisper-cli` with models available.
Output: Rewritten `server/src/voice/transcribe.ts` using local whisper-cli via child_process.
</objective>

<execution_context>
@/Users/developer/.claude/get-shit-done/workflows/execute-plan.md
@/Users/developer/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/19-ai-function-migration/19-RESEARCH.md
@server/src/voice/transcribe.ts
@server/src/routes/voice.ts
@server/src/telegram/handlers/voice.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite transcribeAudio() to use local whisper-cli</name>
  <files>server/src/voice/transcribe.ts</files>
  <action>
Completely rewrite `server/src/voice/transcribe.ts`:

1. **Remove all AI SDK / OpenAI imports:**
   - Remove `import { experimental_transcribe as transcribe } from "ai"`
   - Remove `import { createOpenAI } from "@ai-sdk/openai"`
   - Remove the `openai` provider instance

2. **Add Node.js built-in imports:**
   ```typescript
   import { execFile } from "child_process";
   import { promisify } from "util";
   import { writeFile, unlink } from "fs/promises";
   import { join } from "path";
   import { tmpdir } from "os";
   import { randomUUID } from "crypto";
   ```

3. **Define constants:**
   ```typescript
   const execFileAsync = promisify(execFile);
   const WHISPER_CLI = process.env.WHISPER_CLI_PATH
     || "/Users/developer/whisper.cpp/build/bin/whisper-cli";
   const WHISPER_MODEL = process.env.WHISPER_MODEL_PATH
     || "/Users/developer/whisper.cpp/models/ggml-small.bin";
   ```

4. **Keep the TranscriptionResult interface** exactly as-is (same export shape)

5. **Rewrite transcribeAudio():**
   - Same signature: `async function transcribeAudio(audioBuffer: Buffer, languageHint?: string): Promise<TranscriptionResult>`
   - Write the audio buffer to a temp file: `join(tmpdir(), \`eluma-voice-${randomUUID()}.wav\`)`
   - Build whisper-cli args: `["--model", WHISPER_MODEL, "--no-timestamps", "--threads", "4"]`
   - If languageHint provided: add `"--language", languageHint`
   - Add the temp file path as last arg
   - Call `execFileAsync(WHISPER_CLI, args, { timeout: 60_000 })` (60s max)
   - Extract text from stdout, trim whitespace
   - If text is empty, throw error: "Empty transcription result"
   - Return `{ text, language: languageHint }`
   - In `finally` block: clean up temp file with `unlink(tempPath).catch(() => {})`

6. **Keep the fallback/mock behavior** in the catch block:
   - Log warning: `[voice/transcribe] whisper.cpp failed: ${error.message}`
   - Return mock text (same German/English mock as current implementation)
   - This ensures the voice flow works even if whisper.cpp has issues

7. **Important:** The function signature, return type, and export name must NOT change. Both callers (`routes/voice.ts` and `telegram/handlers/voice.ts`) import `transcribeAudio` by name.
  </action>
  <verify>
1. No AI SDK imports: `grep "from \"ai\"" server/src/voice/transcribe.ts` returns no matches
2. No OpenAI imports: `grep "@ai-sdk/openai" server/src/voice/transcribe.ts` returns no matches
3. No OPENAI_API_KEY: `grep "OPENAI_API_KEY" server/src/voice/transcribe.ts` returns no matches
4. whisper-cli reference: `grep "whisper-cli" server/src/voice/transcribe.ts` returns a match
5. execFile used: `grep "execFile" server/src/voice/transcribe.ts` returns a match
6. Function exported: `grep "export async function transcribeAudio" server/src/voice/transcribe.ts` returns a match
7. Temp cleanup: `grep "unlink" server/src/voice/transcribe.ts` returns a match
8. TypeScript compiles: error count not increased beyond 19
  </verify>
  <done>Voice transcription uses local whisper.cpp. No OpenAI dependency. Temp files are cleaned up. Mock fallback preserved for reliability. Both callers (web upload and Telegram voice) work unchanged.</done>
</task>

</tasks>

<verification>
1. `grep -r "@ai-sdk/openai" server/src/voice/` -- no matches
2. `grep -r "OPENAI_API_KEY" server/src/voice/` -- no matches
3. `grep "whisper-cli\|WHISPER_CLI" server/src/voice/transcribe.ts` -- local binary referenced
4. `grep "export async function transcribeAudio" server/src/voice/transcribe.ts` -- function exported
5. TypeScript error count <= 19
</verification>

<success_criteria>
- transcribeAudio() uses local whisper-cli via child_process.execFile
- No OpenAI API or AI SDK imports in voice/transcribe.ts
- Temp file written, used for transcription, cleaned up in finally block
- Mock fallback on failure preserved for reliability
- Both callers (routes/voice.ts and telegram/handlers/voice.ts) work unchanged
- No new TypeScript errors
</success_criteria>

<output>
After completion, create `.planning/phases/19-ai-function-migration/19-04-SUMMARY.md`
</output>
