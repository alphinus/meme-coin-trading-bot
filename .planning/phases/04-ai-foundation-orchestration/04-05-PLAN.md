---
phase: 04-ai-foundation-orchestration
plan: 05
type: execute
wave: 3
depends_on: ["04-02", "04-03", "04-04"]
files_modified:
  - client/src/hooks/useAiMember.ts
  - client/src/hooks/useAiCost.ts
  - client/src/hooks/useTextToSpeech.ts
  - client/src/components/AiTeamMember.tsx
  - client/src/components/AiCostDashboard.tsx
  - client/src/components/AiModelOverride.tsx
  - client/src/components/AiOverrideMenu.tsx
  - client/src/components/AiMediationView.tsx
  - client/src/components/TextToSpeech.tsx
  - client/src/pages/AiDashboard.tsx
  - client/package.json
autonomous: true

must_haves:
  truths:
    - "AI appears as a named team member on the dashboard with a face emoji when it has something to say"
    - "User can view AI costs per project, per model, and per month in a dashboard widget"
    - "User can manually override the model for any AI task type via the UI"
    - "User can override AI decisions via a slide-on menu with mandatory reason"
    - "AI responses can optionally be read aloud via text-to-speech in German or English"
    - "Mediation results are displayed with both positions and the AI compromise"
  artifacts:
    - path: "client/src/hooks/useAiMember.ts"
      provides: "Hook for AI member config and message status"
      exports: ["useAiMember"]
    - path: "client/src/hooks/useAiCost.ts"
      provides: "Hook for AI cost dashboard data"
      exports: ["useAiCost"]
    - path: "client/src/hooks/useTextToSpeech.ts"
      provides: "Hook for browser-native TTS with language selection"
      exports: ["useTextToSpeech"]
    - path: "client/src/components/AiTeamMember.tsx"
      provides: "AI avatar with face emoji indicator"
      exports: ["AiTeamMember"]
    - path: "client/src/components/AiCostDashboard.tsx"
      provides: "Cost widget with per-project, per-model, per-month breakdown"
      exports: ["AiCostDashboard"]
    - path: "client/src/pages/AiDashboard.tsx"
      provides: "AI overview page combining all AI UI components"
      exports: ["default"]
  key_links:
    - from: "client/src/hooks/useAiMember.ts"
      to: "/api/ai/config"
      via: "apiCall fetch"
      pattern: "api/ai/config"
    - from: "client/src/hooks/useAiCost.ts"
      to: "/api/ai/cost"
      via: "apiCall fetch"
      pattern: "api/ai/cost"
    - from: "client/src/components/AiTeamMember.tsx"
      to: "client/src/hooks/useAiMember.ts"
      via: "useAiMember hook"
      pattern: "useAiMember"
    - from: "client/src/hooks/useTextToSpeech.ts"
      to: "easy-speech"
      via: "EasySpeech.init and EasySpeech.speak"
      pattern: "EasySpeech"
---

<objective>
Build all client-side AI UI components: AI team member display with face emoji, cost dashboard widget, model override selector, decision override slide-on menu, mediation view, text-to-speech controls, and the AI dashboard page.

Purpose: This implements the user-facing side of AI-01 (visible team member), AI-02 (face emoji), AI-03 (TTS), AI-08 (model override UI), AI-09 (cost dashboard), AI-10 (decision override menu), and AI-11 (mediation view). All the API endpoints exist from Plans 02-04; this plan builds the React components and hooks that consume them.

Output: 3 hooks, 6 components, 1 page, easy-speech installed
</objective>

<execution_context>
@/Users/developer/.claude/get-shit-done/workflows/execute-plan.md
@/Users/developer/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-ai-foundation-orchestration/04-RESEARCH.md

# Client patterns from Phase 3
@eluma/client/src/hooks/useSoulDocument.ts
@eluma/client/src/api/client.ts
@eluma/client/src/components/SoulDocumentEntry.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install easy-speech and create AI hooks (useAiMember, useAiCost, useTextToSpeech)</name>
  <files>
    client/package.json
    client/src/hooks/useAiMember.ts
    client/src/hooks/useAiCost.ts
    client/src/hooks/useTextToSpeech.ts
  </files>
  <action>
1. Install easy-speech in client workspace:
   ```
   npm install easy-speech -w client
   ```

2. Create `client/src/hooks/useAiMember.ts`:
   - Follow same pattern as useSoulDocument.ts (useCallback, useEffect, state)
   - Import apiCall from "../api/client.js"
   - State: config (AiMemberConfig | null), loading, error
   - `fetchConfig(teamId: string)`: GET /api/ai/config/{teamId}
   - `updateConfig(teamId: string, data: { name, character, language })`: POST /api/ai/config/{teamId}
   - `fetchStatus(teamId: string)`: GET /api/ai/status/{teamId} -- returns { hasMessage, faceEmoji, pendingMessageId }
   - `markMessageRead(teamId: string)`: POST /api/ai/message-read/{teamId}
   - Auto-fetch config on mount when teamId provided
   - Auto-poll status every 30 seconds (matches existing polling pattern from Phase 1 activity feed)
   - Return { config, status: { hasMessage, faceEmoji }, loading, error, updateConfig, markMessageRead, refresh }

3. Create `client/src/hooks/useAiCost.ts`:
   - State: summary (CostSummary | null), loading, error
   - `fetchCost()`: GET /api/ai/cost -- returns full cost summary
   - `fetchCostForProject(projectId: string)`: GET /api/ai/cost/{projectId}
   - Auto-fetch on mount
   - Return { summary, loading, error, refresh, fetchCostForProject }

4. Create `client/src/hooks/useTextToSpeech.ts`:
   - Import EasySpeech from "easy-speech"
   - useState for ready (boolean), speaking (boolean)
   - useEffect on mount: call EasySpeech.init({ maxTimeout: 5000, interval: 250 }), set ready on success, false on failure
   - speak(text: string) function:
     a. If not ready, return
     b. Get voices via EasySpeech.voices()
     c. Select voice matching language parameter: "de" -> "de-DE", "en" -> "en-US"
     d. Fall back to first available voice
     e. Set speaking true, call EasySpeech.speak({ text, voice, rate: 1, pitch: 1, volume: 1 }), set speaking false in finally
   - stop() function: EasySpeech.cancel(), set speaking false
   - Return { ready, speaking, speak, stop }
   - Accept language parameter: "de" | "en"
  </action>
  <verify>
    Run `cd /Users/developer/eluma && npx tsc --build --noEmit` -- TypeScript compiles. Verify easy-speech appears in client/package.json dependencies. Verify all three hooks export correctly and use apiCall for fetching.
  </verify>
  <done>
    easy-speech installed. Three hooks created: useAiMember (config + status polling), useAiCost (cost summary), useTextToSpeech (browser TTS with DE/EN voice selection). All follow established hook patterns.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create AI components and AiDashboard page</name>
  <files>
    client/src/components/AiTeamMember.tsx
    client/src/components/AiCostDashboard.tsx
    client/src/components/AiModelOverride.tsx
    client/src/components/AiOverrideMenu.tsx
    client/src/components/AiMediationView.tsx
    client/src/components/TextToSpeech.tsx
    client/src/pages/AiDashboard.tsx
  </files>
  <action>
1. Create `client/src/components/AiTeamMember.tsx` (AI-01, AI-02):
   - Props: teamId: string
   - Use useAiMember hook
   - Display: AI member name, a circular avatar with the AI's initial letter, and current face emoji
   - Face emoji mapping (client-side): "idle" -> no indicator, "thinking" -> thinking face, "suggestion" -> lightbulb, "warning" -> warning sign, "mediation" -> balance scale. Use Unicode characters, not emoji library.
   - When hasMessage is true, show a pulsing dot indicator (CSS animation via inline styles) next to the emoji
   - On click when hasMessage: call markMessageRead and show the pending message
   - Include "Configure" link that shows an inline edit form for name, character, and language
   - Configuration form: text input for name (max 50 chars), textarea for character (max 500 chars), select for language (de/en). Submit calls updateConfig.
   - Style: calm, clean card with subtle border. Match existing component styles (see SoulDocumentEntry.tsx for reference).

2. Create `client/src/components/AiCostDashboard.tsx` (AI-09):
   - Props: none (fetches own data)
   - Use useAiCost hook
   - Display three sections:
     a. **Total Cost:** Large number formatted as currency (e.g., "$12.45")
     b. **By Model:** Table rows showing model name and cost
     c. **By Month:** Table rows showing month (YYYY-MM) and cost
   - If no cost data, show "No AI costs recorded yet" message
   - Format costs to 4 decimal places for small amounts, 2 for larger
   - Style: card layout with sections separated by subtle dividers

3. Create `client/src/components/AiModelOverride.tsx` (AI-08):
   - Props: none
   - Display a list of AI task types with their current model assignments (from TASK_MODEL_MAP, hardcoded client-side copy)
   - For each task type, show a select dropdown with available models:
     - "anthropic:fast", "anthropic:balanced", "anthropic:powerful"
     - "openai:fast", "openai:balanced", "openai:powerful"
   - On change: POST /api/ai/override-model with { nodeId: taskType, modelId: selected value }
   - Show success/error feedback inline
   - Optional reason field (textarea, collapsed by default)
   - Style: table layout with task type, current model, and override selector columns

4. Create `client/src/components/AiOverrideMenu.tsx` (AI-10):
   - Props: aiEventId: string, onClose: () => void, visible: boolean
   - Slide-on menu from the right (CSS transform translateX, inline styles)
   - Contains:
     a. Header: "Override AI Decision"
     b. Reason textarea (required, min 1 char): "Why are you overriding this decision?"
     c. New decision textarea (required): "What should the decision be instead?"
     d. Submit button: POST /api/ai/override-decision
     e. Cancel button: calls onClose
   - Show success message on submit, then auto-close after 2 seconds
   - Style: white panel, full height, 400px wide, subtle shadow on left edge. Overlay behind (semi-transparent) to focus attention.

5. Create `client/src/components/AiMediationView.tsx` (AI-11):
   - Props: mediationResult: { text: string, eventId: string } | null, position1: { userId: string, summary: string }, position2: { userId: string, summary: string }
   - Display both positions in side-by-side cards (or stacked on mobile)
   - Display the AI compromise text below using react-markdown (Markdown from react-markdown/v10 default export)
   - Include a TextToSpeech button next to the compromise text
   - Style: position cards with subtle background colors (one light blue, one light green), compromise in a highlighted card

6. Create `client/src/components/TextToSpeech.tsx` (AI-03):
   - Props: text: string, language: "de" | "en"
   - Use useTextToSpeech hook
   - Display: a small button with a speaker icon (Unicode character)
   - When clicked: if not speaking, call speak(text). If speaking, call stop().
   - Show different icon when speaking vs idle
   - If not ready (TTS unavailable), hide the button entirely
   - Style: inline button, small, unobtrusive

7. Create `client/src/pages/AiDashboard.tsx`:
   - Import all components: AiTeamMember, AiCostDashboard, AiModelOverride
   - Use useAuth to get current user, useTeam to get teamId
   - Layout:
     a. Header: "AI Team Member"
     b. Left column (2/3): AiTeamMember card (shows config + emoji status)
     c. Right column (1/3): AiCostDashboard widget
     d. Below: AiModelOverride (full width)
   - Grid layout using CSS grid (inline styles): 2 columns on desktop, 1 on mobile (media query or min-width check)
   - Empty state if no team: "Join a team to configure your AI team member"
  </action>
  <verify>
    Run `cd /Users/developer/eluma && npx tsc --build --noEmit` -- TypeScript compiles. Verify all 6 components and 1 page export correctly. Verify AiTeamMember uses useAiMember hook. Verify AiCostDashboard uses useAiCost hook. Verify TextToSpeech uses useTextToSpeech hook. Verify AiDashboard imports and renders key components.
  </verify>
  <done>
    AI team member visible with face emoji (AI-01, AI-02). Cost dashboard shows per-project/model/month breakdown (AI-09). Model override UI lets users change models per task type (AI-08). Decision override slide-on menu with mandatory reason (AI-10). Mediation view shows positions and compromise (AI-11). TTS button available on AI responses (AI-03). AiDashboard page combines all components.
  </done>
</task>

</tasks>

<verification>
- `npx tsc --build --noEmit` passes from project root
- easy-speech in client/package.json
- All 3 hooks fetch from correct API endpoints
- useAiMember polls status every 30 seconds
- useTextToSpeech handles voice loading via EasySpeech.init
- AiTeamMember shows face emoji with pulsing indicator when hasMessage
- AiCostDashboard renders cost breakdown
- AiOverrideMenu slides in from right with mandatory reason
- AiDashboard combines components in grid layout
</verification>

<success_criteria>
- AI member visible on dashboard with configurable name and face emoji indicator
- Cost dashboard widget shows costs per project, per model, per month
- Model override UI allows changing model per task type
- Decision override available via slide-on menu with audit trail
- TTS reads AI responses in German or English via browser speech synthesis
- Mediation results display both positions and AI compromise
- All components follow existing app styling patterns (clean, calm, not playful)
</success_criteria>

<output>
After completion, create `.planning/phases/04-ai-foundation-orchestration/04-05-SUMMARY.md`
</output>
