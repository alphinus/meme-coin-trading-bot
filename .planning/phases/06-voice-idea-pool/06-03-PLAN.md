---
phase: 06-voice-idea-pool
plan: 03
type: execute
wave: 3
depends_on: ["06-01", "06-02"]
files_modified:
  - client/src/api/client.ts
  - client/src/hooks/useVoiceRecorder.ts
  - client/src/hooks/useIdeaPool.ts
  - client/src/components/VoiceRecorder.tsx
  - client/src/components/IdeaCard.tsx
  - client/src/components/IdeaRefinement.tsx
  - client/src/components/IdeaGraduation.tsx
  - client/src/pages/IdeaPool.tsx
autonomous: true

must_haves:
  truths:
    - "User can click a record button, speak, and stop recording to produce an audio blob"
    - "User can record audio and see transcription text appear within seconds"
    - "User sees a list of their team's ideas with status, readiness score, and title"
    - "User can enter a refinement chat where AI asks questions and they answer"
    - "User can propose graduation and team members can vote approve/reject on the same screen"
    - "Idea Pool page composes all components into a cohesive voice-first experience"
  artifacts:
    - path: "client/src/api/client.ts"
      provides: "apiUpload helper for FormData uploads"
      contains: "apiUpload"
    - path: "client/src/hooks/useVoiceRecorder.ts"
      provides: "useVoiceRecorder hook (recording, audioBlob, startRecording, stopRecording)"
      exports: ["useVoiceRecorder"]
    - path: "client/src/hooks/useIdeaPool.ts"
      provides: "useIdeaPool hook (ideas, createIdea, refine, answer, vote, archive)"
      exports: ["useIdeaPool"]
    - path: "client/src/components/VoiceRecorder.tsx"
      provides: "VoiceRecorder component with record/stop button and upload"
      exports: ["default"]
    - path: "client/src/components/IdeaCard.tsx"
      provides: "IdeaCard component showing idea summary"
      exports: ["default"]
    - path: "client/src/components/IdeaRefinement.tsx"
      provides: "IdeaRefinement component for AI Q&A chat"
      exports: ["default"]
    - path: "client/src/components/IdeaGraduation.tsx"
      provides: "IdeaGraduation component for voting"
      exports: ["default"]
    - path: "client/src/pages/IdeaPool.tsx"
      provides: "IdeaPool page composing all idea components"
      exports: ["default"]
  key_links:
    - from: "client/src/components/VoiceRecorder.tsx"
      to: "/api/voice/transcribe"
      via: "apiUpload with FormData"
      pattern: "apiUpload.*voice/transcribe"
    - from: "client/src/hooks/useIdeaPool.ts"
      to: "/api/ideas"
      via: "apiCall for CRUD operations"
      pattern: "apiCall.*ideas"
    - from: "client/src/components/IdeaRefinement.tsx"
      to: "/api/ideas/:id/refine and /answer"
      via: "useIdeaPool hook functions"
      pattern: "refine|answer"
    - from: "client/src/pages/IdeaPool.tsx"
      to: "VoiceRecorder, IdeaCard, IdeaRefinement, IdeaGraduation"
      via: "component composition"
      pattern: "VoiceRecorder|IdeaCard|IdeaRefinement|IdeaGraduation"
    - from: "client/src/pages/IdeaPool.tsx"
      to: "/api/soul-documents/:userId/entries"
      via: "apiCall POST to append voice input to project Soul Document when routing to existing project"
      pattern: "soul-documents.*entries"
---

<objective>
Build all client-side components for the Idea Pool: voice recording, idea management, AI refinement chat, and graduation voting.

Purpose: Provides the user-facing interface for Phase 6's core workflow -- capturing ideas by voice, viewing and managing the idea pool, engaging in AI-driven refinement conversations, and voting to graduate ideas into full projects.

Output: Complete client-side implementation of IdeaPool page with VoiceRecorder, IdeaCard, IdeaRefinement, and IdeaGraduation components, plus apiUpload helper and two new hooks.
</objective>

<execution_context>
@/Users/developer/.claude/get-shit-done/workflows/execute-plan.md
@/Users/developer/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-voice-idea-pool/06-RESEARCH.md
@.planning/phases/06-voice-idea-pool/06-01-SUMMARY.md
@.planning/phases/06-voice-idea-pool/06-02-SUMMARY.md

# Existing client patterns to follow
@client/src/api/client.ts
@client/src/hooks/useAuth.ts
@client/src/hooks/useTextToSpeech.ts
@client/src/pages/SoulDocument.tsx
@client/src/pages/Dashboard.tsx
@client/src/App.tsx
@shared/types/idea.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add apiUpload helper and build useVoiceRecorder hook + VoiceRecorder component</name>
  <files>
    client/src/api/client.ts
    client/src/hooks/useVoiceRecorder.ts
    client/src/components/VoiceRecorder.tsx
  </files>
  <action>
    **Update `client/src/api/client.ts`:**

    Add a new `apiUpload` function alongside the existing `apiCall`. This handles FormData uploads where Content-Type must NOT be set manually (browser sets multipart boundary):

    ```typescript
    export async function apiUpload<T>(
      url: string,
      formData: FormData
    ): Promise<ApiResponse<T>> {
      try {
        const response = await fetch(url, {
          method: 'POST',
          credentials: 'same-origin',
          body: formData,
          // DO NOT set Content-Type header -- browser auto-generates with boundary
        });
        const json = await response.json();
        if (!response.ok || json.success === false) {
          return { success: false, error: json.error || `HTTP ${response.status}` };
        }
        const data = json.data !== undefined ? json.data : json;
        return { success: true, data: data as T };
      } catch (err) {
        return { success: false, error: err instanceof Error ? err.message : 'Upload failed' };
      }
    }
    ```

    **Create `client/src/hooks/useVoiceRecorder.ts`:**

    Custom hook wrapping the browser's native MediaRecorder API. Follow the pattern from 06-RESEARCH.md:

    - State: `recording` (boolean), `audioBlob` (Blob | null), `error` (string | null), `duration` (number, seconds)
    - Refs: `mediaRecorder` (MediaRecorder | null), `chunks` (Blob[]), `startTime` (number), `durationInterval` (timer)
    - `startRecording()`:
      1. Check `navigator.mediaDevices` exists (set error if not)
      2. Call `navigator.mediaDevices.getUserMedia({ audio: true })`
      3. Handle NotAllowedError and NotFoundError with user-friendly messages
      4. Detect best MIME type: try `audio/webm;codecs=opus`, then `audio/webm`, then `audio/mp4`
      5. Create MediaRecorder with detected mimeType
      6. Wire ondataavailable to push chunks
      7. Wire onstop to create Blob and release mic tracks
      8. Start recording with 1000ms timeslice
      9. Start duration counter (setInterval every 1s)
    - `stopRecording()`: Stop the recorder, clear duration interval
    - `clearRecording()`: Reset audioBlob and error to null, duration to 0
    - Return: `{ recording, audioBlob, error, duration, startRecording, stopRecording, clearRecording }`

    Max recording duration: 5 minutes (300 seconds). Auto-stop if exceeded.

    **Create `client/src/components/VoiceRecorder.tsx`:**

    A self-contained voice recording widget. Props:
    ```typescript
    interface VoiceRecorderProps {
      onTranscription: (text: string) => void;
      onError?: (error: string) => void;
      language?: 'de' | 'en';
    }
    ```

    UI structure:
    1. Record button (large, circular, red when recording)
    2. Duration display when recording (MM:SS format)
    3. "Processing..." state while uploading/transcribing
    4. When audioBlob exists (post-recording): "Transcribe" button
    5. On transcribe click: create FormData, append blob as 'audio' with filename 'recording.webm', call `apiUpload('/api/voice/transcribe?language={lang}', formData)`, call `onTranscription(result.text)` on success
    6. Error display if recording or transcription fails
    7. Also provide a text input fallback: textarea with "Or type your idea..." placeholder and a Submit button, which calls `onTranscription(textValue)` directly

    Style: Clean, calm (matching app aesthetic). Use inline styles following existing pattern. The record button should be visually prominent but not playful.
  </action>
  <verify>
    Run `npx tsc --noEmit`. Verify files exist:
    ```bash
    grep "apiUpload" client/src/api/client.ts
    ls client/src/hooks/useVoiceRecorder.ts
    ls client/src/components/VoiceRecorder.tsx
    ```
  </verify>
  <done>
    apiUpload handles FormData without Content-Type header. useVoiceRecorder wraps MediaRecorder with error handling, MIME detection, duration tracking, and 5-min auto-stop. VoiceRecorder component provides record/stop/transcribe UI with text fallback input.
  </done>
</task>

<task type="auto">
  <name>Task 2: Build useIdeaPool hook, IdeaCard, IdeaRefinement, and IdeaGraduation components</name>
  <files>
    client/src/hooks/useIdeaPool.ts
    client/src/components/IdeaCard.tsx
    client/src/components/IdeaRefinement.tsx
    client/src/components/IdeaGraduation.tsx
  </files>
  <action>
    **Create `client/src/hooks/useIdeaPool.ts`:**

    Follow the pattern of existing hooks (useProject, useSoulDocument):

    ```typescript
    interface UseIdeaPoolReturn {
      ideas: IdeaState[];
      loading: boolean;
      error: string | null;
      selectedIdea: IdeaState | null;
      // Actions
      fetchIdeas: () => Promise<void>;
      createIdea: (teamId: string, title: string, rawInput: string, source: 'text' | 'voice') => Promise<IdeaState | null>;
      selectIdea: (ideaId: string) => Promise<void>;
      refineIdea: (ideaId: string, language?: 'de' | 'en') => Promise<{ question: string } | null>;
      answerRefinement: (ideaId: string, answer: string, language?: 'de' | 'en') => Promise<{ readinessScore: number; missing: string[]; recommendation: string } | null>;
      overrideReady: (ideaId: string) => Promise<void>;
      proposeGraduation: (ideaId: string) => Promise<void>;
      voteOnGraduation: (ideaId: string, approve: boolean) => Promise<{ graduated: boolean; projectId?: string } | null>;
      archiveIdea: (ideaId: string) => Promise<void>;
      routeVoice: (text: string, teamId: string, language?: 'de' | 'en') => Promise<RoutingSuggestion[] | null>;
    }
    ```

    Each action calls the corresponding API endpoint via `apiCall` and updates local state. `fetchIdeas` takes teamId from the user's team (pass as parameter or read from hook). Use `useCallback` for memoization. Use `useEffect` for initial fetch.

    Import the RoutingSuggestion type -- define it in the hook file (or import from a shared location if convenient):
    ```typescript
    interface RoutingSuggestion {
      type: 'existing_project' | 'idea_pool';
      projectId?: string;
      projectName?: string;
      confidence: number;
      reasoning: string;
    }
    ```

    **Create `client/src/components/IdeaCard.tsx`:**

    Displays a single idea in the pool as a card. Props: `idea: IdeaState, onClick: () => void`

    Card shows:
    - Title (idea.title) -- bold
    - Status badge (colored pill: capturing=gray, refining=blue, ready=green, voting=amber, graduated=emerald, archived=gray)
    - Readiness score as a small bar or number (e.g., "72/100")
    - Creation date (formatted)
    - Refinement rounds count (e.g., "3/7 rounds")
    - If graduated: "Graduated to project" link

    Style: Card with subtle border and shadow (follow existing card patterns in Dashboard). Clickable -- whole card is the click target.

    **Create `client/src/components/IdeaRefinement.tsx`:**

    Chat-like interface for the AI refinement loop. Props:
    ```typescript
    interface IdeaRefinementProps {
      idea: IdeaState;
      onRefine: (ideaId: string) => Promise<{ question: string } | null>;
      onAnswer: (ideaId: string, answer: string) => Promise<{ readinessScore: number; missing: string[]; recommendation: string } | null>;
      onOverrideReady: (ideaId: string) => Promise<void>;
      language?: 'de' | 'en';
    }
    ```

    UI:
    1. Readiness score bar at top (0-100, color gradient: red < 40, amber 40-69, green >= 70)
    2. Display refined markdown content using react-markdown (import Markdown from 'react-markdown', same v10 pattern used in SoulDocument)
    3. "Ask AI" button to trigger the next refinement question (disabled if rounds >= maxRounds or status !== 'refining')
    4. When question appears: display it in a distinct AI message bubble (light blue background)
    5. Text area for user's answer below the question
    6. "Submit Answer" button (emits answer, then shows updated score)
    7. Show "missing" items as a checklist after each assessment
    8. "Mark as Ready" button (manual override, shown when status is 'refining')
    9. If readinessScore >= 70 or manually overridden: show "Ready for Graduation" message

    **Create `client/src/components/IdeaGraduation.tsx`:**

    Team voting interface for graduating an idea. Props:
    ```typescript
    interface IdeaGraduationProps {
      idea: IdeaState;
      currentUserId: string;
      teamMembers: Array<{ userId: string; displayName: string; role: string }>;
      onPropose: (ideaId: string) => Promise<void>;
      onVote: (ideaId: string, approve: boolean) => Promise<{ graduated: boolean; projectId?: string } | null>;
    }
    ```

    UI:
    1. If status is 'ready': "Propose Graduation" button
    2. If status is 'voting':
       - Show vote status for each human team member (pending/approved/rejected)
       - If current user hasn't voted: Approve/Reject buttons
       - If current user has voted: show their vote
    3. If graduated: success message with link to the new project (`/projects/{projectId}`)
    4. Filter out AI role members from the voter list (only human team members vote)
  </action>
  <verify>
    Run `npx tsc --noEmit`. Verify all files:
    ```bash
    ls client/src/hooks/useIdeaPool.ts
    ls client/src/components/IdeaCard.tsx
    ls client/src/components/IdeaRefinement.tsx
    ls client/src/components/IdeaGraduation.tsx
    ```
  </verify>
  <done>
    useIdeaPool hook wraps all API calls for idea CRUD, refinement, graduation, and voice routing. IdeaCard shows idea summary with status and readiness. IdeaRefinement provides chat-like AI Q&A with readiness scoring. IdeaGraduation shows team voting with approve/reject and auto-graduation on unanimous approval.
  </done>
</task>

<task type="auto">
  <name>Task 3: Build IdeaPool page composing all components</name>
  <files>
    client/src/pages/IdeaPool.tsx
  </files>
  <action>
    **Create `client/src/pages/IdeaPool.tsx`:**

    The main page for the Idea Pool. Composes VoiceRecorder, IdeaCard, IdeaRefinement, and IdeaGraduation into a cohesive experience.

    Component structure:
    ```
    IdeaPool page
    ├── Header: "Idea Pool" title
    ├── VoiceRecorder (always visible at top -- voice-first input)
    │   └── On transcription: show routing suggestions or create new idea
    ├── Routing suggestions panel (shown after transcription)
    │   └── List of suggestions: "Route to Project X (85% confidence)" or "Add to Idea Pool"
    │   └── User clicks to confirm routing
    ├── Idea list (grid of IdeaCards, filtered by team)
    │   └── Clicking a card selects it
    ├── Selected idea detail panel (shown when an idea is selected)
    │   ├── IdeaRefinement (if status is capturing/refining)
    │   └── IdeaGraduation (if status is ready/voting/graduated)
    ```

    State management:
    - Use `useIdeaPool` hook for all idea operations
    - Use `useAuth` to get current user and their team
    - Use `useTeam` (or derive teamId from user context) to get team members for graduation voting
    - Track: `selectedIdeaId`, `showRoutingSuggestions`, `routingSuggestions`, `transcribedText`

    Flow when user records voice:
    1. VoiceRecorder captures audio and transcribes
    2. onTranscription callback receives text
    3. Call `routeVoice(text, teamId, language)` to get suggestions
    4. Show routing panel with suggestions
    5. If user picks "Idea Pool": call `createIdea(teamId, '', text, 'voice')` (title auto-generated by AI on server -- the transcription_added event sets the title, but for now the initial creation can have a placeholder title derived from first 50 chars of text)
    6. If user picks an existing project: call `apiCall('POST', '/api/soul-documents/${userId}/entries', { content: text, sourceType: 'audio', projectId })` to append the voice input to the user's Soul Document linked to that project, show a success toast, then navigate to `/projects/${projectId}`. This wires the routing to actual data creation — the voice input is preserved as a Soul Document entry with the `audio` source type (already supported by EntrySourceType).

    Flow when user types text:
    1. VoiceRecorder's text fallback calls onTranscription with typed text
    2. Same routing flow as above

    Layout:
    - Two-column on desktop (lg): left = idea list, right = detail/refinement
    - Single column on mobile: list above, detail below
    - Use max-width container (e.g., 1200px, centered)
    - VoiceRecorder spans full width above the two columns

    Use inline styles following existing patterns. Import `useAuth` from hooks. Import `useTeam` or `apiCall` for team member data. If `useTeam` doesn't exist as a standalone hook, fetch team members via `apiCall('GET', '/api/teams/{teamId}')` inside a useEffect.
  </action>
  <verify>
    Run `npx tsc --noEmit`. Verify the page exists and imports components:
    ```bash
    grep "VoiceRecorder\|IdeaCard\|IdeaRefinement\|IdeaGraduation" client/src/pages/IdeaPool.tsx
    ```
  </verify>
  <done>
    IdeaPool page composes all components into a voice-first experience. Recording triggers transcription then routing. Ideas are listed as cards. Selecting an idea shows refinement or graduation interface depending on status. Layout is responsive.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with no errors
2. `apiUpload` is exported from `client/src/api/client.ts`
3. `useVoiceRecorder` handles recording, error states, MIME detection, and auto-stop
4. `VoiceRecorder` shows record button, duration, transcribe, and text fallback
5. `useIdeaPool` wraps all API calls for ideas
6. `IdeaCard` displays title, status, readiness, and rounds
7. `IdeaRefinement` shows AI questions, accepts answers, displays readiness score
8. `IdeaGraduation` shows vote status and handles propose/vote flow
9. `IdeaPool` page composes all components with voice-first capture and routing
</verification>

<success_criteria>
All client components compile and compose correctly. Voice recording produces audio blob. Transcription result triggers routing or idea creation. Refinement chat allows AI Q&A. Graduation voting shows all team members' status.
</success_criteria>

<output>
After completion, create `.planning/phases/06-voice-idea-pool/06-03-SUMMARY.md`
</output>
