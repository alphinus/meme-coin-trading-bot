---
phase: 06-voice-idea-pool
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - shared/types/idea.ts
  - shared/types/events.ts
  - shared/types/ai.ts
  - server/src/ai/config.ts
  - server/src/voice/transcribe.ts
  - server/src/routes/voice.ts
  - server/src/events/reducers/idea.ts
  - server/src/routes/ideas.ts
  - server/package.json
autonomous: true

must_haves:
  truths:
    - "Idea types are defined and importable from shared/types/idea.ts"
    - "New idea_pool event types are registered in EventType union and EVENT_TYPES array"
    - "Audio file uploaded via POST /api/voice/transcribe returns transcription text"
    - "Idea CRUD operations work through event-sourced reducer"
    - "Ideas can be created, listed, and fetched by ID via REST API"
  artifacts:
    - path: "shared/types/idea.ts"
      provides: "IdeaState, IdeaStatus, IdeaEventType interfaces"
      contains: "IdeaState"
    - path: "shared/types/events.ts"
      provides: "Updated EventType union with idea.* events"
      contains: "idea.created"
    - path: "shared/types/ai.ts"
      provides: "Updated AiTaskType with idea_refinement, idea_readiness, voice_routing"
      contains: "idea_refinement"
    - path: "server/src/voice/transcribe.ts"
      provides: "transcribeAudio function wrapping AI SDK experimental_transcribe"
      exports: ["transcribeAudio"]
    - path: "server/src/routes/voice.ts"
      provides: "POST /api/voice/transcribe endpoint with multer"
      exports: ["default"]
    - path: "server/src/events/reducers/idea.ts"
      provides: "reduceIdeaState, getIdeaById, getAllIdeas, getIdeasForTeam"
      exports: ["reduceIdeaState", "getIdeaById", "getAllIdeas", "getIdeasForTeam"]
    - path: "server/src/routes/ideas.ts"
      provides: "CRUD routes for ideas (create, list, get by ID)"
      exports: ["default"]
  key_links:
    - from: "server/src/voice/transcribe.ts"
      to: "ai SDK experimental_transcribe"
      via: "import from 'ai'"
      pattern: "experimental_transcribe"
    - from: "server/src/routes/voice.ts"
      to: "server/src/voice/transcribe.ts"
      via: "transcribeAudio function call"
      pattern: "transcribeAudio"
    - from: "server/src/events/reducers/idea.ts"
      to: "server/src/events/store.ts"
      via: "readEvents('idea_pool')"
      pattern: "readEvents.*idea_pool"
    - from: "server/src/routes/ideas.ts"
      to: "server/src/events/reducers/idea.ts"
      via: "getIdeaById, getAllIdeas"
      pattern: "getIdeaById|getAllIdeas"
---

<objective>
Build the foundational types, voice transcription pipeline, and idea event-sourced aggregate for Phase 6.

Purpose: Establishes the shared type contracts (IdeaState, event types, AI task types), the server-side audio transcription capability using AI SDK's experimental_transcribe with multer for file upload, and the Idea Pool entity as a new event-sourced aggregate following the existing JSONL reducer pattern.

Output: Shared types importable by server and client, working POST /api/voice/transcribe endpoint, working CRUD API for ideas at /api/ideas.
</objective>

<execution_context>
@/Users/developer/.claude/get-shit-done/workflows/execute-plan.md
@/Users/developer/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-voice-idea-pool/06-RESEARCH.md

# Existing patterns to follow
@shared/types/events.ts
@shared/types/models.ts
@shared/types/ai.ts
@server/src/events/reducers/project.ts
@server/src/events/store.ts
@server/src/routes/projects.ts
@server/src/ai/generate.ts
@server/src/ai/config.ts
@server/src/app.ts
@client/src/api/client.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Define shared types for Idea Pool and extend event/AI types</name>
  <files>
    shared/types/idea.ts
    shared/types/events.ts
    shared/types/ai.ts
    server/src/ai/config.ts
  </files>
  <action>
    **Create `shared/types/idea.ts`:**

    Define the following types (follow models.ts naming patterns):

    ```typescript
    export type IdeaStatus = 'capturing' | 'refining' | 'ready' | 'voting' | 'graduated' | 'archived';

    export interface IdeaState {
      id: string;
      teamId: string;
      createdBy: string;
      title: string;                    // AI-generated from initial input
      rawInput: string;                 // Original transcription or text
      refinedMarkdown: string;          // Current refined state (grows with each Q&A round)
      readinessScore: number;           // 0-100, AI-assessed
      refinementRounds: number;         // How many Q&A rounds completed
      maxRefinementRounds: number;      // Cap at 7
      status: IdeaStatus;
      votes: Record<string, boolean>;   // userId -> approve/reject
      projectId?: string;               // Set when graduated
      createdAt: string;
      updatedAt: string;
    }
    ```

    Also export `READINESS_THRESHOLD = 70` and `MAX_REFINEMENT_ROUNDS = 7` as named constants.

    **Update `shared/types/events.ts`:**

    Add these to the `EventType` union:
    - `"idea.created"`
    - `"idea.transcription_added"`
    - `"idea.refinement_question"`
    - `"idea.refinement_answer"`
    - `"idea.readiness_assessed"`
    - `"idea.graduation_proposed"`
    - `"idea.graduation_voted"`
    - `"idea.graduated"`
    - `"idea.archived"`

    Add the same 9 strings to the `EVENT_TYPES` const array.

    **Update `shared/types/ai.ts`:**

    Extend the `AiTaskType` union to include:
    - `"idea_refinement"`
    - `"idea_readiness"`
    - `"voice_routing"`

    **IMPORTANT:** After extending `AiTaskType`, update `server/src/ai/config.ts` to add temperature and max token presets for the 3 new task types:
    - `idea_refinement`: temperature 0.5, maxTokens 800
    - `idea_readiness`: temperature 0.2, maxTokens 500
    - `voice_routing`: temperature 0.2, maxTokens 400
  </action>
  <verify>
    Run `npx tsc --noEmit` from the project root. No type errors should exist. The new types should be importable:
    ```
    grep "IdeaState" shared/types/idea.ts
    grep "idea.created" shared/types/events.ts
    grep "idea_refinement" shared/types/ai.ts
    ```
  </verify>
  <done>
    IdeaState, IdeaStatus, and constants exported from shared/types/idea.ts. Nine idea.* event types in EventType union and EVENT_TYPES array. Three new AI task types added to AiTaskType with corresponding config presets.
  </done>
</task>

<task type="auto">
  <name>Task 2: Install multer and build voice transcription pipeline</name>
  <files>
    server/package.json
    server/src/voice/transcribe.ts
    server/src/routes/voice.ts
  </files>
  <action>
    **Install multer:**
    ```bash
    cd server && npm install multer && npm install -D @types/multer
    ```

    **Create `server/src/voice/transcribe.ts`:**

    Wrapper around AI SDK's `experimental_transcribe`:

    ```typescript
    import { experimental_transcribe as transcribe } from 'ai';
    import { createOpenAI } from '@ai-sdk/openai';

    const openai = createOpenAI({ apiKey: process.env.OPENAI_API_KEY || '' });

    export interface TranscriptionResult {
      text: string;
      language?: string;
      durationInSeconds?: number;
    }

    export async function transcribeAudio(
      audioBuffer: Buffer,
      languageHint?: string
    ): Promise<TranscriptionResult> {
      const result = await transcribe({
        model: openai.transcription('whisper-1'),
        audio: audioBuffer,
        providerOptions: {
          openai: {
            ...(languageHint && { language: languageHint }),
          },
        },
      });

      return {
        text: result.text,
        language: result.language,
        durationInSeconds: result.durationInSeconds,
      };
    }
    ```

    **Create `server/src/routes/voice.ts`:**

    Express router with multer for multipart upload:

    ```typescript
    import { Router } from 'express';
    import multer from 'multer';
    import { transcribeAudio } from '../voice/transcribe.js';

    const upload = multer({
      storage: multer.memoryStorage(),
      limits: { fileSize: 25 * 1024 * 1024 }, // 25MB Whisper limit
      fileFilter: (_req, file, cb) => {
        const allowed = ['audio/webm', 'audio/ogg', 'audio/mp4', 'audio/mpeg', 'audio/wav', 'audio/x-m4a'];
        cb(null, allowed.includes(file.mimetype));
      },
    });

    const router = Router();

    // POST /api/voice/transcribe
    // Accepts multipart/form-data with 'audio' file field
    // Optional query param: language (ISO-639-1, e.g., 'en' or 'de')
    router.post('/transcribe', upload.single('audio'), async (req, res) => {
      try {
        if (!req.file) {
          return res.status(400).json({ success: false, error: 'No audio file provided' });
        }

        const languageHint = req.query.language as string | undefined;
        const result = await transcribeAudio(req.file.buffer, languageHint);

        res.json({
          success: true,
          data: {
            text: result.text,
            language: result.language,
            durationInSeconds: result.durationInSeconds,
          },
        });
      } catch (error) {
        const message = error instanceof Error ? error.message : String(error);
        console.error('[voice/transcribe] Transcription failed:', message);
        res.status(500).json({ success: false, error: 'Transcription failed' });
      }
    });

    export default router;
    ```

    **IMPORTANT:** Do NOT register the route in app.ts yet -- that happens in Plan 04 (integration plan). Just export the router.
  </action>
  <verify>
    Run `npx tsc --noEmit` from project root. Verify multer is installed:
    ```bash
    ls server/node_modules/multer
    grep "multer" server/package.json
    ```
    Verify files exist:
    ```bash
    ls server/src/voice/transcribe.ts server/src/routes/voice.ts
    ```
  </verify>
  <done>
    multer installed. transcribeAudio wrapper exists and compiles. POST /transcribe route handles multipart upload with file validation, size limit, and error handling. Audio is transcribed server-side via whisper-1.
  </done>
</task>

<task type="auto">
  <name>Task 3: Build idea event-sourced reducer and CRUD API routes</name>
  <files>
    server/src/events/reducers/idea.ts
    server/src/routes/ideas.ts
  </files>
  <action>
    **Create `server/src/events/reducers/idea.ts`:**

    Follow the exact same pattern as `server/src/events/reducers/project.ts`:

    ```typescript
    // Import DomainEvent from shared/types/events.js
    // Import IdeaState, IdeaStatus from shared/types/idea.js
    // Import readEvents from '../store.js'

    export function reduceIdeaState(events: DomainEvent[]): IdeaState | null {
      // If no events, return null
      // Switch on event.type for each idea.* event type:
      //
      // idea.created: Initialize state with id, teamId, createdBy, title, rawInput,
      //   refinedMarkdown (= rawInput initially), readinessScore: 0, refinementRounds: 0,
      //   maxRefinementRounds: 7, status: 'capturing', votes: {}, createdAt, updatedAt
      //
      // idea.transcription_added: Set rawInput and refinedMarkdown from data.text,
      //   set title from data.title (AI-generated), transition status to 'refining'
      //
      // idea.refinement_question: Append AI question to refinedMarkdown
      //   (format: "\n\n### Question {round}\n{question}")
      //
      // idea.refinement_answer: Append user answer to refinedMarkdown
      //   (format: "\n\n**Answer:** {answer}"), increment refinementRounds
      //
      // idea.readiness_assessed: Update readinessScore from data.score,
      //   if score >= READINESS_THRESHOLD -> status = 'ready'
      //
      // idea.graduation_proposed: status = 'voting'
      //
      // idea.graduation_voted: Set votes[data.userId] = data.approve (boolean)
      //
      // idea.graduated: status = 'graduated', projectId = data.projectId
      //
      // idea.archived: status = 'archived'
      //
      // Always update updatedAt on each event
      //
      // Return null if no idea.created event found
    }

    export async function getIdeaById(ideaId: string): Promise<IdeaState | null> {
      const events = await readEvents('idea_pool', ideaId);
      events.sort((a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime());
      return reduceIdeaState(events);
    }

    export async function getAllIdeas(): Promise<IdeaState[]> {
      const allEvents = await readEvents('idea_pool');
      if (allEvents.length === 0) return [];
      // Group by aggregateId, sort each group, reduce each group
      // Same pattern as getAllProjects in project.ts
    }

    export async function getIdeasForTeam(teamId: string): Promise<IdeaState[]> {
      const allIdeas = await getAllIdeas();
      return allIdeas.filter(i => i.teamId === teamId);
    }

    export async function getCurrentIdeaVersion(ideaId: string): Promise<number> {
      const events = await readEvents('idea_pool', ideaId);
      return events.length;
    }
    ```

    **Create `server/src/routes/ideas.ts`:**

    Express router with CRUD endpoints. Follow the pattern in `server/src/routes/projects.ts`:

    - `GET /` -- List ideas for the user's team. Requires `teamId` query param. Returns array of IdeaState.
    - `GET /:id` -- Get single idea by ID. Returns IdeaState or 404.
    - `POST /` -- Create a new idea. Body: `{ teamId, title, rawInput, source: 'text' | 'voice' }`.
      - Generate UUID for idea ID and correlationId
      - Emit `idea.created` event with aggregateType `idea_pool` and aggregateId as the new idea ID
      - If source is 'text', also emit `idea.transcription_added` with the raw text as the transcription
        (since text ideas skip the voice step but still need the title/content set)
      - Return the created idea state
    - `POST /:id/archive` -- Archive an idea. Emits `idea.archived` event. Returns updated state.

    Use Zod validation for request bodies (follow existing pattern with `import { z } from 'zod'` and inline schemas).

    Wire `processEventForDocumentation` after each `appendEvent` call (follow the fire-and-forget pattern from projects.ts).

    **IMPORTANT:** Do NOT register the route in app.ts yet -- that happens in Plan 04.
  </action>
  <verify>
    Run `npx tsc --noEmit` from project root. Verify files exist:
    ```bash
    ls server/src/events/reducers/idea.ts server/src/routes/ideas.ts
    ```
    Verify the reducer exports the expected functions:
    ```bash
    grep "export.*function" server/src/events/reducers/idea.ts
    ```
  </verify>
  <done>
    Idea reducer follows project.ts pattern exactly: reduceIdeaState processes all 9 idea.* event types. getIdeaById, getAllIdeas, getIdeasForTeam, getCurrentIdeaVersion exported. Ideas CRUD routes handle create (text or voice source), list, get, and archive with Zod validation and fire-and-forget documentation wiring.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with no errors
2. `shared/types/idea.ts` exports IdeaState, IdeaStatus, READINESS_THRESHOLD, MAX_REFINEMENT_ROUNDS
3. `shared/types/events.ts` contains all 9 idea.* event types in both union and array
4. `shared/types/ai.ts` contains idea_refinement, idea_readiness, voice_routing in AiTaskType
5. `server/src/ai/config.ts` has presets for all 3 new task types
6. `multer` is in server/package.json dependencies
7. `server/src/voice/transcribe.ts` exports transcribeAudio
8. `server/src/routes/voice.ts` exports a router with POST /transcribe
9. `server/src/events/reducers/idea.ts` exports reduceIdeaState, getIdeaById, getAllIdeas, getIdeasForTeam
10. `server/src/routes/ideas.ts` exports a router with GET /, GET /:id, POST /, POST /:id/archive
</verification>

<success_criteria>
All shared types compile. Voice transcription pipeline is functional (multer + AI SDK). Idea aggregate reducer processes all event types correctly. CRUD API routes for ideas are complete with validation.
</success_criteria>

<output>
After completion, create `.planning/phases/06-voice-idea-pool/06-01-SUMMARY.md`
</output>
